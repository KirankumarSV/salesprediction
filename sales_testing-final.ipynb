{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "018585e8",
   "metadata": {},
   "source": [
    "### data/preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731b39e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b354204",
   "metadata": {},
   "source": [
    "### utils/logger.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd6d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def setup_logging():\n",
    "    logging.basicConfig(\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        level=logging.INFO\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67da8b5",
   "metadata": {},
   "source": [
    "### data/preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0859d25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "class FillMissingValues(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.median_competition_distance = X['competition_distance'].median()\n",
    "        self.mode_competition_open_since_year = X['competition_open_since_year'].mode()[0]\n",
    "        self.mode_competition_open_since_month = X['competition_open_since_month'].mode()[0]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X['competition_distance'].fillna(self.median_competition_distance, inplace=True)\n",
    "        X['competition_open_since_year'].fillna(self.mode_competition_open_since_year, inplace=True)\n",
    "        X['competition_open_since_month'].fillna(self.mode_competition_open_since_month, inplace=True)\n",
    "        X['promo2_since_week'].fillna(0, inplace=True)\n",
    "        X['promo2_since_year'].fillna(0, inplace=True)\n",
    "        X['promo_interval'].fillna(0, inplace=True)\n",
    "        return X\n",
    "\n",
    "class EncodeScaleData(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.assortment_dict = {'a': 1, 'b': 2, 'c': 3}\n",
    "        self.minmax_scaler = MinMaxScaler()\n",
    "        self.standard_scaler = StandardScaler()\n",
    "        self.ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        self.column_transformer = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        # Fit OneHotEncoder and LabelEncoder\n",
    "        self.ohe.fit(X[['state_holiday']])\n",
    "        self.label_encoder.fit(X['store_type'])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        # Apply OneHotEncoder to state_holiday\n",
    "        state_holiday_encoded = self.ohe.transform(X[['state_holiday']])\n",
    "        state_holiday_encoded_df = pd.DataFrame(state_holiday_encoded, columns=self.ohe.get_feature_names_out(['state_holiday']))\n",
    "\n",
    "        # Apply LabelEncoder to store_type\n",
    "        X['store_type'] = self.label_encoder.transform(X['store_type'])\n",
    "        X['assortment'] = X['assortment'].map(self.assortment_dict)\n",
    "\n",
    "        # Scaling numerical features\n",
    "        X[['year', 'promo2_since']] = self.minmax_scaler.fit_transform(X[['year', 'promo2_since']])\n",
    "        X[['competition_distance', 'competition_open']] = self.minmax_scaler.fit_transform(X[['competition_distance', 'competition_open']])\n",
    "        if 'customers' in X.columns:\n",
    "            X[['customers']] = self.standard_scaler.fit_transform(X[['customers']]\n",
    "\n",
    "        # Drop original state_holiday column and concatenate encoded dataframe\n",
    "        X = X.drop(columns=['state_holiday'])\n",
    "        X = pd.concat([X.reset_index(drop=True), state_holiday_encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1157fe5",
   "metadata": {},
   "source": [
    "### feature_engineering/feature_engineering.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2631844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        months = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun',\n",
    "                  7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "        X['is_promo'] = X.apply(lambda x: 0 if x['promo_interval'] == 0 else 1 if months[x['date'].month] in x['promo_interval'].split(\",\") else 0, axis=1)\n",
    "        X['day'] = X['date'].dt.day\n",
    "        X['month'] = X['date'].dt.month  # Ensure month column is created\n",
    "        X['year'] = X['date'].dt.year\n",
    "        X['week_of_year'] = X['date'].dt.isocalendar().week\n",
    "        X['competition_open'] = (X['year'] - X['competition_open_since_year']) * 12 - X['competition_open_since_month'] + X['month']\n",
    "        X['competition_open'] = X['competition_open'].apply(lambda x: 0 if x < 0 else x)\n",
    "        promo2_conditional_difference = np.where(X['promo2_since_year'] != 0, X['year'] - X['promo2_since_year'], 0)\n",
    "        X['promo2_since'] = (promo2_conditional_difference) * 52 + X['week_of_year'] - X['promo2_since_week']\n",
    "        X['promo2_since'] = X['promo2_since'].apply(lambda x: max(x, 0))\n",
    "        X['state_holiday'] = X['state_holiday'].astype(str)\n",
    "        X['store_type'] = X['store_type'].astype(str)\n",
    "        X['assortment'] = X['assortment'].astype(str)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return self.columns_.tolist()\n",
    "\n",
    "\n",
    "class CyclicalFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, max_values):\n",
    "        self.columns = columns\n",
    "        self.max_values = max_values\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        for column, max_value in zip(self.columns, self.max_values):\n",
    "            X[column + '_sin'] = np.sin(2 * np.pi * X[column] / max_value)\n",
    "            X[column + '_cos'] = np.cos(2 * np.pi * X[column] / max_value)\n",
    "        return X.drop(columns=self.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df630f3b",
   "metadata": {},
   "source": [
    "### feature_engineering/drop_columns.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ab4f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        return X.drop(columns=self.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ceec87",
   "metadata": {},
   "source": [
    "### feature_engineering/transformations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3b7d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_engineering/transformations.py\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class ApplyTransformations(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, small_constant=1):\n",
    "        self.small_constant = small_constant\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        \n",
    "        #apply sqrt transformation on customers    \n",
    "        if 'customers' in X.columns:\n",
    "            X['customers'] = np.sqrt(X['customers'])\n",
    "\n",
    "        # Apply log1p transformation to 'competition_distance'\n",
    "        if 'competition_distance' in X.columns:\n",
    "            X['competition_distance'] = np.log1p(X['competition_distance'])\n",
    "\n",
    "        # Apply log transformation with a small constant to handle zeros in 'competition_open' and 'promo2_since'\n",
    "        if 'competition_open' in X.columns:\n",
    "            X['competition_open'] = np.log1p(X['competition_open'] + self.small_constant)\n",
    "        if 'promo2_since' in X.columns:\n",
    "            X['promo2_since'] = np.log1p(X['promo2_since'] + self.small_constant)\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f490f32",
   "metadata": {},
   "source": [
    "### model/target_transformer.py     NOT REQUIRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12091ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model/target_transformer.py\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# import numpy as np\n",
    "\n",
    "# class TargetTransformer(BaseEstimator, TransformerMixin):\n",
    "#     def fit(self, y):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, y):\n",
    "#         return np.sqrt(y)\n",
    "\n",
    "#     def inverse_transform(self, y):\n",
    "#         return np.square(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b7b55",
   "metadata": {},
   "source": [
    "### model/vif_selector.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7312c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class VIFSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=5):\n",
    "        self.threshold = threshold\n",
    "        self.columns_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        \n",
    "        print(\"Initial number of columns:\", X.shape[1])  # Debug print\n",
    "        \n",
    "        high_vif = True\n",
    "        while high_vif:\n",
    "            vif_values = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "            max_vif = max(vif_values)\n",
    "            print(\"Current max VIF:\", max_vif)  # Debug print\n",
    "            if max_vif > self.threshold:\n",
    "                max_vif_index = vif_values.index(max_vif)\n",
    "                column_to_drop = X.columns[max_vif_index]\n",
    "                print(\"Dropping column:\", column_to_drop)  # Debug print\n",
    "                X = X.drop(columns=[column_to_drop])\n",
    "            else:\n",
    "                high_vif = False\n",
    "        self.columns_ = X.columns\n",
    "        print(\"Final number of columns:\", X.shape[1])  # Debug print\n",
    "        return X\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return self.columns_.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155589b",
   "metadata": {},
   "source": [
    "### model/select_k_best.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f86dfcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "# import pandas as pd\n",
    "\n",
    "# class SelectKBestFeatures(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, k='all'):\n",
    "#         self.k = k\n",
    "#         self.selector = SelectKBest(score_func=mutual_info_regression, k=k)\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         self.selector.fit(X, y)\n",
    "#         self.columns_ = X.columns[self.selector.get_support()]\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y=None):\n",
    "#         return X[self.columns_]\n",
    "    \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import mutual_info_regression, SelectKBest\n",
    "import pandas as pd\n",
    "\n",
    "class SelectKBestFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k='all', threshold=0.005):\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "        self.feature_scores_ = None  # Use trailing underscore to follow sklearn convention\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.selector = SelectKBest(score_func=mutual_info_regression, k='all')\n",
    "        self.selector.fit(X, y)\n",
    "        \n",
    "        # Get the scores and identify features with low mutual information\n",
    "        scores = self.selector.scores_\n",
    "        self.feature_scores_ = pd.DataFrame({'feature': X.columns, 'score': scores})\n",
    "        self.columns_ = self.feature_scores_[self.feature_scores_['score'] > self.threshold]['feature'].values\n",
    "        print(\"Select K best features done\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.columns_]\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return self.columns_\n",
    "\n",
    "    def get_feature_scores(self):\n",
    "        return self.feature_scores_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6c5827",
   "metadata": {},
   "source": [
    "### app/pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b66f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app/pipeline.py\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from data.preprocessing import FillMissingValues, EncodeScaleData\n",
    "# from feature_engineering.feature_engineering import FeatureEngineering, CyclicalFeatures\n",
    "# from feature_engineering.transformations import ApplyTransformations  # Import the new transformer\n",
    "# from feature_engineering.drop_columns import DropColumns\n",
    "# from model.vif_selector import VIFSelector\n",
    "# from model.select_k_best import SelectKBestFeatures\n",
    "# from model.inverse_transformations import InverseSalesTransformation  # Import the inverse transformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "def sqrt_transform_with_constant(y, constant=10):\n",
    "    return np.sqrt(y + constant)\n",
    "\n",
    "def inverse_sqrt_transform_with_constant(y, constant=10):\n",
    "    return np.square(y) - constant\n",
    "\n",
    "class ConvertToFloat64(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.astype('float64')\n",
    "\n",
    "def create_pipeline():\n",
    "    preprocessing_pipeline = Pipeline(steps=[\n",
    "        ('fill_missing', FillMissingValues()),\n",
    "        ('feature_engineering', FeatureEngineering()),\n",
    "        ('cyclical_features', CyclicalFeatures(columns=['month', 'day_of_week', 'day', 'week_of_year'], max_values=[12, 7, 31, 52])),\n",
    "        ('apply_transformations', ApplyTransformations()),  # Add the new transformer\n",
    "        ('encode_scale', EncodeScaleData())\n",
    "    ])\n",
    "    \n",
    "    vif_pipeline = Pipeline(steps=[\n",
    "        ('drop_columns', DropColumns(columns=['date', 'competition_open_since_month', 'competition_open_since_year', 'promo2_since_week', \n",
    "                                              'promo2_since_year', 'promo_interval'])),\n",
    "        ('convert_to_float64', ConvertToFloat64()),\n",
    "        ('vif', VIFSelector(threshold=5))\n",
    "    ])\n",
    "    \n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('vif', vif_pipeline),\n",
    "        ('select_k_best', SelectKBestFeatures(k='all', threshold=0.005)),\n",
    "        ('model',  RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "    ])\n",
    "    \n",
    "    final_pipeline = TransformedTargetRegressor(\n",
    "        regressor=model_pipeline,\n",
    "        func=sqrt_transform_with_constant,\n",
    "        inverse_func=inverse_sqrt_transform_with_constant\n",
    "    )\n",
    "    \n",
    "    return final_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6e5fb1",
   "metadata": {},
   "source": [
    "### model/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49aec9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import pickle\n",
    "# from datetime import datetime\n",
    "# # from app.pipeline import create_pipeline\n",
    "\n",
    "# # Function to get the CSV file path from the input directory\n",
    "# def get_csv_path(input_dir='input'):\n",
    "#     for file_name in os.listdir(input_dir):\n",
    "#         if file_name.endswith('sales_data.csv'):\n",
    "#             return os.path.join(input_dir, file_name)\n",
    "#     raise FileNotFoundError(\"No CSV file found in the input directory.\")\n",
    "\n",
    "# # Custom date parser that tries multiple formats\n",
    "# # def custom_date_parser(x):\n",
    "# #     for fmt in ('%d-%m-%Y', '%Y-%m-%d'):\n",
    "# #         try:\n",
    "# #             return datetime.strptime(x, fmt)\n",
    "# #         except ValueError:\n",
    "# #             pass\n",
    "# #     raise ValueError(f\"no valid date format found for {x}\")\n",
    "\n",
    "# # # Function to apply the custom date parser\n",
    "# # def parse_dates(date_series):\n",
    "# #     return date_series.apply(custom_date_parser)\n",
    "\n",
    "# # Specify dtypes to avoid DtypeWarning\n",
    "# dtype_spec = {\n",
    "#     'store': int,\n",
    "#     'day_of_week': int,\n",
    "#     'sales': float,\n",
    "#     'customers': int,\n",
    "#     'open': int,\n",
    "#     'promo': int,\n",
    "#     'state_holiday': str,\n",
    "#     'school_holiday': int,\n",
    "#     'store_type': str,\n",
    "#     'assortment': str,\n",
    "#     'competition_distance': float,\n",
    "#     'competition_open_since_month': float,\n",
    "#     'competition_open_since_year': float,\n",
    "#     'promo2': int,\n",
    "#     'promo2_since_week': float,\n",
    "#     'promo2_since_year': float,\n",
    "#     'promo_interval': str\n",
    "# }\n",
    "\n",
    "# # Train and save the pipeline\n",
    "# csv_path = get_csv_path()  # Dynamically get the CSV path\n",
    "# df = pd.read_csv(csv_path, dtype=dtype_spec, low_memory=False, parse_dates=['date'])\n",
    "\n",
    "# # # Convert the date column using the custom date parser\n",
    "# # df['date'] = parse_dates(df['date'])\n",
    "\n",
    "# X = df.drop(columns=['sales'])\n",
    "# y = df['sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e70a36d",
   "metadata": {},
   "source": [
    "### utils/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b69c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def get_csv_path(input_dir='input', filename='sales_data.csv'):\n",
    "    import os\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith(filename):\n",
    "            return os.path.join(input_dir, file_name)\n",
    "    raise FileNotFoundError(f\"No CSV file found in the input directory: {input_dir}\")\n",
    "\n",
    "def custom_date_parser(x):\n",
    "    for fmt in ('%d-%m-%Y', '%Y-%m-%d'):\n",
    "        try:\n",
    "            return datetime.strptime(x, fmt)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    raise ValueError(f\"No valid date format found for {x}\")\n",
    "\n",
    "def parse_dates(date_series):\n",
    "    return date_series.apply(custom_date_parser)\n",
    "\n",
    "def save_model(pipeline, filename='model_pipeline.pkl'):\n",
    "    import pickle\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(pipeline, f)\n",
    "\n",
    "def load_model(filename='model_pipeline.pkl'):\n",
    "    import pickle\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad3cb5",
   "metadata": {},
   "source": [
    "### scripts/run_training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "770dad2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 00:46:23,244 - root - INFO - Starting training process\n",
      "2024-07-11 00:46:25,732 - root - INFO - Creating pipeline\n",
      "2024-07-11 00:46:25,733 - root - INFO - Fitting pipeline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of columns: 25\n",
      "Current max VIF: 45.34305812996274\n",
      "Dropping column: week_of_year_cos\n",
      "Current max VIF: 42.69405553988109\n",
      "Dropping column: state_holiday_0\n",
      "Current max VIF: 40.23264243624885\n",
      "Dropping column: week_of_year_sin\n",
      "Current max VIF: 17.62879154609724\n",
      "Dropping column: open\n",
      "Current max VIF: 7.360765662392768\n",
      "Dropping column: competition_distance\n",
      "Current max VIF: 6.211694904522429\n",
      "Dropping column: promo2_since\n",
      "Current max VIF: 3.717989604629969\n",
      "Final number of columns: 19\n",
      "Select K best features done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 01:07:10,087 - root - INFO - Pipeline fitted successfully\n",
      "2024-07-11 01:07:10,136 - root - INFO - Saving the trained model\n",
      "2024-07-11 01:10:59,992 - root - INFO - Model saved successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.utils import get_csv_path, save_model\n",
    "from app.pipeline import create_pipeline\n",
    "from utils.logger import setup_logging\n",
    "import logging\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def run_training():\n",
    "    setup_logging()\n",
    "    logging.info(\"Starting training process\")\n",
    "\n",
    "\n",
    "        # Load the data\n",
    "    csv_path = get_csv_path()\n",
    "    dtype_spec = {\n",
    "        'store': int,\n",
    "        'day_of_week': int,\n",
    "        'sales': float,\n",
    "        'customers': int,\n",
    "        'open': int,\n",
    "        'promo': int,\n",
    "        'state_holiday': str,\n",
    "        'school_holiday': int,\n",
    "        'store_type': str,\n",
    "        'assortment': str,\n",
    "        'competition_distance': float,\n",
    "        'competition_open_since_month': float,\n",
    "        'competition_open_since_year': float,\n",
    "        'promo2': int,\n",
    "        'promo2_since_week': float,\n",
    "        'promo2_since_year': float,\n",
    "        'promo_interval': str\n",
    "    }\n",
    "    df = pd.read_csv(csv_path, dtype=dtype_spec, low_memory=False, parse_dates=['date'])\n",
    "\n",
    "    X = df.drop(columns=['sales'])\n",
    "    y = df['sales']\n",
    "\n",
    "    logging.info(\"Creating pipeline\")\n",
    "    pipeline = create_pipeline()\n",
    "\n",
    "    logging.info(\"Fitting pipeline\")\n",
    "    pipeline.fit(X, y)\n",
    "    logging.info(\"Pipeline fitted successfully\")\n",
    "\n",
    "    logging.info(\"Saving the trained model\")\n",
    "    save_model(pipeline)\n",
    "    logging.info(\"Model saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5b49b03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 09:54:30,802 - root - INFO - Making predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of columns: 25\n",
      "Current max VIF: 45.34305812996274\n",
      "Dropping column: week_of_year_cos\n",
      "Current max VIF: 42.69405553988109\n",
      "Dropping column: state_holiday_0\n",
      "Current max VIF: 40.23264243624885\n",
      "Dropping column: week_of_year_sin\n",
      "Current max VIF: 17.62879154609724\n",
      "Dropping column: open\n",
      "Current max VIF: 7.360765662392768\n",
      "Dropping column: competition_distance\n",
      "Current max VIF: 6.211694904522429\n",
      "Dropping column: promo2_since\n",
      "Current max VIF: 3.717989604629969\n",
      "Final number of columns: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 10:05:12,123 - root - INFO - Calculating performance metrics\n",
      "2024-07-11 10:05:12,281 - root - INFO - Model performance metrics calculated\n",
      "2024-07-11 10:05:12,286 - root - INFO - R^2: 0.9975497156681291\n",
      "2024-07-11 10:05:12,288 - root - INFO - Adjusted R^2: 0.9975496747172815\n",
      "2024-07-11 10:05:12,289 - root - INFO - MAE: 110.7221579619695\n",
      "2024-07-11 10:05:12,291 - root - INFO - RMSE: 190.5725870978322\n",
      "2024-07-11 10:05:12,292 - root - INFO - Saving performance metrics to file\n",
      "2024-07-11 10:05:12,417 - root - INFO - Performance metrics saved successfully\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Making predictions\")\n",
    "y_pred = pipeline.predict(X)\n",
    "\n",
    "# Post-prediction adjustment to ensure sales are never less than zero\n",
    "y_pred_adjusted = np.maximum(y_pred, 0)\n",
    "\n",
    "# Include both X and y_pred in the same DataFrame\n",
    "predictions_df = X.copy()\n",
    "predictions_df['predicted_sales'] = y_pred_adjusted\n",
    "predictions_df['actual_sales'] = y\n",
    "\n",
    "#defining adjusted r2\n",
    "def calculate_adjusted_r2(r2, n, k):\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
    "\n",
    "# Calculate metrics\n",
    "logging.info(\"Calculating performance metrics\")\n",
    "r2 = r2_score(y, y_pred_adjusted)\n",
    "adjusted_r2 = calculate_adjusted_r2(r2, X.shape[0], X.shape[1])\n",
    "mae = mean_absolute_error(y, y_pred_adjusted)\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred_adjusted))\n",
    "\n",
    "metrics = {\n",
    "    'R^2': r2,\n",
    "    'Adjusted R^2': adjusted_r2,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse\n",
    "}\n",
    "\n",
    "logging.info(\"Model performance metrics calculated\")\n",
    "for metric, value in metrics.items():\n",
    "    logging.info(f\"{metric}: {value}\")\n",
    "\n",
    "# Optionally, save metrics to a file\n",
    "logging.info(\"Saving performance metrics to file\")\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "metrics_df.to_csv('model_performance_metrics.csv', index=False)\n",
    "logging.info(\"Performance metrics saved successfully\")\n",
    "\n",
    "#     return predictions_df\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     predictions_df = run_training()\n",
    "#     print(predictions_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec5f1eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['y_pred'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "818233c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>date</th>\n",
       "      <th>customers</th>\n",
       "      <th>open</th>\n",
       "      <th>promo</th>\n",
       "      <th>state_holiday</th>\n",
       "      <th>school_holiday</th>\n",
       "      <th>store_type</th>\n",
       "      <th>assortment</th>\n",
       "      <th>competition_distance</th>\n",
       "      <th>competition_open_since_month</th>\n",
       "      <th>competition_open_since_year</th>\n",
       "      <th>promo2</th>\n",
       "      <th>promo2_since_week</th>\n",
       "      <th>promo2_since_year</th>\n",
       "      <th>promo_interval</th>\n",
       "      <th>predicted_sales</th>\n",
       "      <th>actual_sales</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [store, day_of_week, date, customers, open, promo, state_holiday, school_holiday, store_type, assortment, competition_distance, competition_open_since_month, competition_open_since_year, promo2, promo2_since_week, promo2_since_year, promo_interval, predicted_sales, actual_sales, y_pred]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df[(predictions_df['predicted_sales'] < 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb2902cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TransformedTargetRegressor' object has no attribute 'named_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17772\\1568260169.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'TransformedTargetRegressor' object has no attribute 'named_steps'"
     ]
    }
   ],
   "source": [
    "pipeline.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = predictions_df.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, linecolor='black')\n",
    "plt.title('Correlation Heatmap of Selected Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38dfbfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>7520.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Store  DayOfWeek        Date  Open  Promo StateHoliday  SchoolHoliday  \\\n",
       "0   1      1          4  2015-09-17   1.0      1            0              0   \n",
       "1   2      3          4  2015-09-17   1.0      1            0              0   \n",
       "2   3      7          4  2015-09-17   1.0      1            0              0   \n",
       "3   4      8          4  2015-09-17   1.0      1            0              0   \n",
       "4   5      9          4  2015-09-17   1.0      1            0              0   \n",
       "\n",
       "  StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
       "0         c          a               1270.0                        9.0   \n",
       "1         a          a              14130.0                       12.0   \n",
       "2         a          c              24000.0                        4.0   \n",
       "3         a          a               7520.0                       10.0   \n",
       "4         a          c               2030.0                        8.0   \n",
       "\n",
       "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
       "0                    2008.0       0              NaN              NaN   \n",
       "1                    2006.0       1             14.0           2011.0   \n",
       "2                    2013.0       0              NaN              NaN   \n",
       "3                    2014.0       0              NaN              NaN   \n",
       "4                    2000.0       0              NaN              NaN   \n",
       "\n",
       "     PromoInterval  \n",
       "0              NaN  \n",
       "1  Jan,Apr,Jul,Oct  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"E://Learnbay Project/salesprediction/input/test.csv\")\n",
    "store = pd.read_csv(\"E://Learnbay Project/salesprediction/input/store.csv\")\n",
    "test_data = pd.merge(left= test, right= store, how= \"left\", on= \"Store\")\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "455489dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The snake_case columns after renaming will be:  \n",
      " \n",
      " ['id', 'store', 'day_of_week', 'date', 'open', 'promo', 'state_holiday', 'school_holiday', 'store_type', 'assortment', 'competition_distance', 'competition_open_since_month', 'competition_open_since_year', 'promo2', 'promo2_since_week', 'promo2_since_year', 'promo_interval']\n"
     ]
    }
   ],
   "source": [
    "import inflection\n",
    "\n",
    "snakecase = lambda x : inflection.underscore(x)\n",
    "new_columns = list(map(snakecase, test_data.columns))\n",
    "print(\"The snake_case columns after renaming will be:  \\n \\n\", new_columns)\n",
    "\n",
    "#Renaming the columns in snake case\n",
    "test_data.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67053796",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(['id'],axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71b318a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>promo</th>\n",
       "      <th>state_holiday</th>\n",
       "      <th>school_holiday</th>\n",
       "      <th>store_type</th>\n",
       "      <th>assortment</th>\n",
       "      <th>competition_distance</th>\n",
       "      <th>competition_open_since_month</th>\n",
       "      <th>competition_open_since_year</th>\n",
       "      <th>promo2</th>\n",
       "      <th>promo2_since_week</th>\n",
       "      <th>promo2_since_year</th>\n",
       "      <th>promo_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>7520.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  day_of_week        date  open  promo state_holiday  school_holiday  \\\n",
       "0      1            4  2015-09-17   1.0      1             0               0   \n",
       "1      3            4  2015-09-17   1.0      1             0               0   \n",
       "2      7            4  2015-09-17   1.0      1             0               0   \n",
       "3      8            4  2015-09-17   1.0      1             0               0   \n",
       "4      9            4  2015-09-17   1.0      1             0               0   \n",
       "\n",
       "  store_type assortment  competition_distance  competition_open_since_month  \\\n",
       "0          c          a                1270.0                           9.0   \n",
       "1          a          a               14130.0                          12.0   \n",
       "2          a          c               24000.0                           4.0   \n",
       "3          a          a                7520.0                          10.0   \n",
       "4          a          c                2030.0                           8.0   \n",
       "\n",
       "   competition_open_since_year  promo2  promo2_since_week  promo2_since_year  \\\n",
       "0                       2008.0       0                NaN                NaN   \n",
       "1                       2006.0       1               14.0             2011.0   \n",
       "2                       2013.0       0                NaN                NaN   \n",
       "3                       2014.0       0                NaN                NaN   \n",
       "4                       2000.0       0                NaN                NaN   \n",
       "\n",
       "    promo_interval  \n",
       "0              NaN  \n",
       "1  Jan,Apr,Jul,Oct  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "121d5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"E://Learnbay Project/salesprediction/input/test_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c45c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
